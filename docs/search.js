window.pdocSearch = (function(){
/** elasticlunr - http://weixsong.github.io * Copyright (C) 2017 Oliver Nightingale * Copyright (C) 2017 Wei Song * MIT Licensed */!function(){function e(e){if(null===e||"object"!=typeof e)return e;var t=e.constructor();for(var n in e)e.hasOwnProperty(n)&&(t[n]=e[n]);return t}var t=function(e){var n=new t.Index;return n.pipeline.add(t.trimmer,t.stopWordFilter,t.stemmer),e&&e.call(n,n),n};t.version="0.9.5",lunr=t,t.utils={},t.utils.warn=function(e){return function(t){e.console&&console.warn&&console.warn(t)}}(this),t.utils.toString=function(e){return void 0===e||null===e?"":e.toString()},t.EventEmitter=function(){this.events={}},t.EventEmitter.prototype.addListener=function(){var e=Array.prototype.slice.call(arguments),t=e.pop(),n=e;if("function"!=typeof t)throw new TypeError("last argument must be a function");n.forEach(function(e){this.hasHandler(e)||(this.events[e]=[]),this.events[e].push(t)},this)},t.EventEmitter.prototype.removeListener=function(e,t){if(this.hasHandler(e)){var n=this.events[e].indexOf(t);-1!==n&&(this.events[e].splice(n,1),0==this.events[e].length&&delete this.events[e])}},t.EventEmitter.prototype.emit=function(e){if(this.hasHandler(e)){var t=Array.prototype.slice.call(arguments,1);this.events[e].forEach(function(e){e.apply(void 0,t)},this)}},t.EventEmitter.prototype.hasHandler=function(e){return e in this.events},t.tokenizer=function(e){if(!arguments.length||null===e||void 0===e)return[];if(Array.isArray(e)){var n=e.filter(function(e){return null===e||void 0===e?!1:!0});n=n.map(function(e){return t.utils.toString(e).toLowerCase()});var i=[];return n.forEach(function(e){var n=e.split(t.tokenizer.seperator);i=i.concat(n)},this),i}return e.toString().trim().toLowerCase().split(t.tokenizer.seperator)},t.tokenizer.defaultSeperator=/[\s\-]+/,t.tokenizer.seperator=t.tokenizer.defaultSeperator,t.tokenizer.setSeperator=function(e){null!==e&&void 0!==e&&"object"==typeof e&&(t.tokenizer.seperator=e)},t.tokenizer.resetSeperator=function(){t.tokenizer.seperator=t.tokenizer.defaultSeperator},t.tokenizer.getSeperator=function(){return t.tokenizer.seperator},t.Pipeline=function(){this._queue=[]},t.Pipeline.registeredFunctions={},t.Pipeline.registerFunction=function(e,n){n in t.Pipeline.registeredFunctions&&t.utils.warn("Overwriting existing registered function: "+n),e.label=n,t.Pipeline.registeredFunctions[n]=e},t.Pipeline.getRegisteredFunction=function(e){return e in t.Pipeline.registeredFunctions!=!0?null:t.Pipeline.registeredFunctions[e]},t.Pipeline.warnIfFunctionNotRegistered=function(e){var n=e.label&&e.label in this.registeredFunctions;n||t.utils.warn("Function is not registered with pipeline. This may cause problems when serialising the index.\n",e)},t.Pipeline.load=function(e){var n=new t.Pipeline;return e.forEach(function(e){var i=t.Pipeline.getRegisteredFunction(e);if(!i)throw new Error("Cannot load un-registered function: "+e);n.add(i)}),n},t.Pipeline.prototype.add=function(){var e=Array.prototype.slice.call(arguments);e.forEach(function(e){t.Pipeline.warnIfFunctionNotRegistered(e),this._queue.push(e)},this)},t.Pipeline.prototype.after=function(e,n){t.Pipeline.warnIfFunctionNotRegistered(n);var i=this._queue.indexOf(e);if(-1===i)throw new Error("Cannot find existingFn");this._queue.splice(i+1,0,n)},t.Pipeline.prototype.before=function(e,n){t.Pipeline.warnIfFunctionNotRegistered(n);var i=this._queue.indexOf(e);if(-1===i)throw new Error("Cannot find existingFn");this._queue.splice(i,0,n)},t.Pipeline.prototype.remove=function(e){var t=this._queue.indexOf(e);-1!==t&&this._queue.splice(t,1)},t.Pipeline.prototype.run=function(e){for(var t=[],n=e.length,i=this._queue.length,o=0;n>o;o++){for(var r=e[o],s=0;i>s&&(r=this._queue[s](r,o,e),void 0!==r&&null!==r);s++);void 0!==r&&null!==r&&t.push(r)}return t},t.Pipeline.prototype.reset=function(){this._queue=[]},t.Pipeline.prototype.get=function(){return this._queue},t.Pipeline.prototype.toJSON=function(){return this._queue.map(function(e){return t.Pipeline.warnIfFunctionNotRegistered(e),e.label})},t.Index=function(){this._fields=[],this._ref="id",this.pipeline=new t.Pipeline,this.documentStore=new t.DocumentStore,this.index={},this.eventEmitter=new t.EventEmitter,this._idfCache={},this.on("add","remove","update",function(){this._idfCache={}}.bind(this))},t.Index.prototype.on=function(){var e=Array.prototype.slice.call(arguments);return this.eventEmitter.addListener.apply(this.eventEmitter,e)},t.Index.prototype.off=function(e,t){return this.eventEmitter.removeListener(e,t)},t.Index.load=function(e){e.version!==t.version&&t.utils.warn("version mismatch: current "+t.version+" importing "+e.version);var n=new this;n._fields=e.fields,n._ref=e.ref,n.documentStore=t.DocumentStore.load(e.documentStore),n.pipeline=t.Pipeline.load(e.pipeline),n.index={};for(var i in e.index)n.index[i]=t.InvertedIndex.load(e.index[i]);return n},t.Index.prototype.addField=function(e){return this._fields.push(e),this.index[e]=new t.InvertedIndex,this},t.Index.prototype.setRef=function(e){return this._ref=e,this},t.Index.prototype.saveDocument=function(e){return this.documentStore=new t.DocumentStore(e),this},t.Index.prototype.addDoc=function(e,n){if(e){var n=void 0===n?!0:n,i=e[this._ref];this.documentStore.addDoc(i,e),this._fields.forEach(function(n){var o=this.pipeline.run(t.tokenizer(e[n]));this.documentStore.addFieldLength(i,n,o.length);var r={};o.forEach(function(e){e in r?r[e]+=1:r[e]=1},this);for(var s in r){var u=r[s];u=Math.sqrt(u),this.index[n].addToken(s,{ref:i,tf:u})}},this),n&&this.eventEmitter.emit("add",e,this)}},t.Index.prototype.removeDocByRef=function(e){if(e&&this.documentStore.isDocStored()!==!1&&this.documentStore.hasDoc(e)){var t=this.documentStore.getDoc(e);this.removeDoc(t,!1)}},t.Index.prototype.removeDoc=function(e,n){if(e){var n=void 0===n?!0:n,i=e[this._ref];this.documentStore.hasDoc(i)&&(this.documentStore.removeDoc(i),this._fields.forEach(function(n){var o=this.pipeline.run(t.tokenizer(e[n]));o.forEach(function(e){this.index[n].removeToken(e,i)},this)},this),n&&this.eventEmitter.emit("remove",e,this))}},t.Index.prototype.updateDoc=function(e,t){var t=void 0===t?!0:t;this.removeDocByRef(e[this._ref],!1),this.addDoc(e,!1),t&&this.eventEmitter.emit("update",e,this)},t.Index.prototype.idf=function(e,t){var n="@"+t+"/"+e;if(Object.prototype.hasOwnProperty.call(this._idfCache,n))return this._idfCache[n];var i=this.index[t].getDocFreq(e),o=1+Math.log(this.documentStore.length/(i+1));return this._idfCache[n]=o,o},t.Index.prototype.getFields=function(){return this._fields.slice()},t.Index.prototype.search=function(e,n){if(!e)return[];e="string"==typeof e?{any:e}:JSON.parse(JSON.stringify(e));var i=null;null!=n&&(i=JSON.stringify(n));for(var o=new t.Configuration(i,this.getFields()).get(),r={},s=Object.keys(e),u=0;u<s.length;u++){var a=s[u];r[a]=this.pipeline.run(t.tokenizer(e[a]))}var l={};for(var c in o){var d=r[c]||r.any;if(d){var f=this.fieldSearch(d,c,o),h=o[c].boost;for(var p in f)f[p]=f[p]*h;for(var p in f)p in l?l[p]+=f[p]:l[p]=f[p]}}var v,g=[];for(var p in l)v={ref:p,score:l[p]},this.documentStore.hasDoc(p)&&(v.doc=this.documentStore.getDoc(p)),g.push(v);return g.sort(function(e,t){return t.score-e.score}),g},t.Index.prototype.fieldSearch=function(e,t,n){var i=n[t].bool,o=n[t].expand,r=n[t].boost,s=null,u={};return 0!==r?(e.forEach(function(e){var n=[e];1==o&&(n=this.index[t].expandToken(e));var r={};n.forEach(function(n){var o=this.index[t].getDocs(n),a=this.idf(n,t);if(s&&"AND"==i){var l={};for(var c in s)c in o&&(l[c]=o[c]);o=l}n==e&&this.fieldSearchStats(u,n,o);for(var c in o){var d=this.index[t].getTermFrequency(n,c),f=this.documentStore.getFieldLength(c,t),h=1;0!=f&&(h=1/Math.sqrt(f));var p=1;n!=e&&(p=.15*(1-(n.length-e.length)/n.length));var v=d*a*h*p;c in r?r[c]+=v:r[c]=v}},this),s=this.mergeScores(s,r,i)},this),s=this.coordNorm(s,u,e.length)):void 0},t.Index.prototype.mergeScores=function(e,t,n){if(!e)return t;if("AND"==n){var i={};for(var o in t)o in e&&(i[o]=e[o]+t[o]);return i}for(var o in t)o in e?e[o]+=t[o]:e[o]=t[o];return e},t.Index.prototype.fieldSearchStats=function(e,t,n){for(var i in n)i in e?e[i].push(t):e[i]=[t]},t.Index.prototype.coordNorm=function(e,t,n){for(var i in e)if(i in t){var o=t[i].length;e[i]=e[i]*o/n}return e},t.Index.prototype.toJSON=function(){var e={};return this._fields.forEach(function(t){e[t]=this.index[t].toJSON()},this),{version:t.version,fields:this._fields,ref:this._ref,documentStore:this.documentStore.toJSON(),index:e,pipeline:this.pipeline.toJSON()}},t.Index.prototype.use=function(e){var t=Array.prototype.slice.call(arguments,1);t.unshift(this),e.apply(this,t)},t.DocumentStore=function(e){this._save=null===e||void 0===e?!0:e,this.docs={},this.docInfo={},this.length=0},t.DocumentStore.load=function(e){var t=new this;return t.length=e.length,t.docs=e.docs,t.docInfo=e.docInfo,t._save=e.save,t},t.DocumentStore.prototype.isDocStored=function(){return this._save},t.DocumentStore.prototype.addDoc=function(t,n){this.hasDoc(t)||this.length++,this.docs[t]=this._save===!0?e(n):null},t.DocumentStore.prototype.getDoc=function(e){return this.hasDoc(e)===!1?null:this.docs[e]},t.DocumentStore.prototype.hasDoc=function(e){return e in this.docs},t.DocumentStore.prototype.removeDoc=function(e){this.hasDoc(e)&&(delete this.docs[e],delete this.docInfo[e],this.length--)},t.DocumentStore.prototype.addFieldLength=function(e,t,n){null!==e&&void 0!==e&&0!=this.hasDoc(e)&&(this.docInfo[e]||(this.docInfo[e]={}),this.docInfo[e][t]=n)},t.DocumentStore.prototype.updateFieldLength=function(e,t,n){null!==e&&void 0!==e&&0!=this.hasDoc(e)&&this.addFieldLength(e,t,n)},t.DocumentStore.prototype.getFieldLength=function(e,t){return null===e||void 0===e?0:e in this.docs&&t in this.docInfo[e]?this.docInfo[e][t]:0},t.DocumentStore.prototype.toJSON=function(){return{docs:this.docs,docInfo:this.docInfo,length:this.length,save:this._save}},t.stemmer=function(){var e={ational:"ate",tional:"tion",enci:"ence",anci:"ance",izer:"ize",bli:"ble",alli:"al",entli:"ent",eli:"e",ousli:"ous",ization:"ize",ation:"ate",ator:"ate",alism:"al",iveness:"ive",fulness:"ful",ousness:"ous",aliti:"al",iviti:"ive",biliti:"ble",logi:"log"},t={icate:"ic",ative:"",alize:"al",iciti:"ic",ical:"ic",ful:"",ness:""},n="[^aeiou]",i="[aeiouy]",o=n+"[^aeiouy]*",r=i+"[aeiou]*",s="^("+o+")?"+r+o,u="^("+o+")?"+r+o+"("+r+")?$",a="^("+o+")?"+r+o+r+o,l="^("+o+")?"+i,c=new RegExp(s),d=new RegExp(a),f=new RegExp(u),h=new RegExp(l),p=/^(.+?)(ss|i)es$/,v=/^(.+?)([^s])s$/,g=/^(.+?)eed$/,m=/^(.+?)(ed|ing)$/,y=/.$/,S=/(at|bl|iz)$/,x=new RegExp("([^aeiouylsz])\\1$"),w=new RegExp("^"+o+i+"[^aeiouwxy]$"),I=/^(.+?[^aeiou])y$/,b=/^(.+?)(ational|tional|enci|anci|izer|bli|alli|entli|eli|ousli|ization|ation|ator|alism|iveness|fulness|ousness|aliti|iviti|biliti|logi)$/,E=/^(.+?)(icate|ative|alize|iciti|ical|ful|ness)$/,D=/^(.+?)(al|ance|ence|er|ic|able|ible|ant|ement|ment|ent|ou|ism|ate|iti|ous|ive|ize)$/,F=/^(.+?)(s|t)(ion)$/,_=/^(.+?)e$/,P=/ll$/,k=new RegExp("^"+o+i+"[^aeiouwxy]$"),z=function(n){var i,o,r,s,u,a,l;if(n.length<3)return n;if(r=n.substr(0,1),"y"==r&&(n=r.toUpperCase()+n.substr(1)),s=p,u=v,s.test(n)?n=n.replace(s,"$1$2"):u.test(n)&&(n=n.replace(u,"$1$2")),s=g,u=m,s.test(n)){var z=s.exec(n);s=c,s.test(z[1])&&(s=y,n=n.replace(s,""))}else if(u.test(n)){var z=u.exec(n);i=z[1],u=h,u.test(i)&&(n=i,u=S,a=x,l=w,u.test(n)?n+="e":a.test(n)?(s=y,n=n.replace(s,"")):l.test(n)&&(n+="e"))}if(s=I,s.test(n)){var z=s.exec(n);i=z[1],n=i+"i"}if(s=b,s.test(n)){var z=s.exec(n);i=z[1],o=z[2],s=c,s.test(i)&&(n=i+e[o])}if(s=E,s.test(n)){var z=s.exec(n);i=z[1],o=z[2],s=c,s.test(i)&&(n=i+t[o])}if(s=D,u=F,s.test(n)){var z=s.exec(n);i=z[1],s=d,s.test(i)&&(n=i)}else if(u.test(n)){var z=u.exec(n);i=z[1]+z[2],u=d,u.test(i)&&(n=i)}if(s=_,s.test(n)){var z=s.exec(n);i=z[1],s=d,u=f,a=k,(s.test(i)||u.test(i)&&!a.test(i))&&(n=i)}return s=P,u=d,s.test(n)&&u.test(n)&&(s=y,n=n.replace(s,"")),"y"==r&&(n=r.toLowerCase()+n.substr(1)),n};return z}(),t.Pipeline.registerFunction(t.stemmer,"stemmer"),t.stopWordFilter=function(e){return e&&t.stopWordFilter.stopWords[e]!==!0?e:void 0},t.clearStopWords=function(){t.stopWordFilter.stopWords={}},t.addStopWords=function(e){null!=e&&Array.isArray(e)!==!1&&e.forEach(function(e){t.stopWordFilter.stopWords[e]=!0},this)},t.resetStopWords=function(){t.stopWordFilter.stopWords=t.defaultStopWords},t.defaultStopWords={"":!0,a:!0,able:!0,about:!0,across:!0,after:!0,all:!0,almost:!0,also:!0,am:!0,among:!0,an:!0,and:!0,any:!0,are:!0,as:!0,at:!0,be:!0,because:!0,been:!0,but:!0,by:!0,can:!0,cannot:!0,could:!0,dear:!0,did:!0,"do":!0,does:!0,either:!0,"else":!0,ever:!0,every:!0,"for":!0,from:!0,get:!0,got:!0,had:!0,has:!0,have:!0,he:!0,her:!0,hers:!0,him:!0,his:!0,how:!0,however:!0,i:!0,"if":!0,"in":!0,into:!0,is:!0,it:!0,its:!0,just:!0,least:!0,let:!0,like:!0,likely:!0,may:!0,me:!0,might:!0,most:!0,must:!0,my:!0,neither:!0,no:!0,nor:!0,not:!0,of:!0,off:!0,often:!0,on:!0,only:!0,or:!0,other:!0,our:!0,own:!0,rather:!0,said:!0,say:!0,says:!0,she:!0,should:!0,since:!0,so:!0,some:!0,than:!0,that:!0,the:!0,their:!0,them:!0,then:!0,there:!0,these:!0,they:!0,"this":!0,tis:!0,to:!0,too:!0,twas:!0,us:!0,wants:!0,was:!0,we:!0,were:!0,what:!0,when:!0,where:!0,which:!0,"while":!0,who:!0,whom:!0,why:!0,will:!0,"with":!0,would:!0,yet:!0,you:!0,your:!0},t.stopWordFilter.stopWords=t.defaultStopWords,t.Pipeline.registerFunction(t.stopWordFilter,"stopWordFilter"),t.trimmer=function(e){if(null===e||void 0===e)throw new Error("token should not be undefined");return e.replace(/^\W+/,"").replace(/\W+$/,"")},t.Pipeline.registerFunction(t.trimmer,"trimmer"),t.InvertedIndex=function(){this.root={docs:{},df:0}},t.InvertedIndex.load=function(e){var t=new this;return t.root=e.root,t},t.InvertedIndex.prototype.addToken=function(e,t,n){for(var n=n||this.root,i=0;i<=e.length-1;){var o=e[i];o in n||(n[o]={docs:{},df:0}),i+=1,n=n[o]}var r=t.ref;n.docs[r]?n.docs[r]={tf:t.tf}:(n.docs[r]={tf:t.tf},n.df+=1)},t.InvertedIndex.prototype.hasToken=function(e){if(!e)return!1;for(var t=this.root,n=0;n<e.length;n++){if(!t[e[n]])return!1;t=t[e[n]]}return!0},t.InvertedIndex.prototype.getNode=function(e){if(!e)return null;for(var t=this.root,n=0;n<e.length;n++){if(!t[e[n]])return null;t=t[e[n]]}return t},t.InvertedIndex.prototype.getDocs=function(e){var t=this.getNode(e);return null==t?{}:t.docs},t.InvertedIndex.prototype.getTermFrequency=function(e,t){var n=this.getNode(e);return null==n?0:t in n.docs?n.docs[t].tf:0},t.InvertedIndex.prototype.getDocFreq=function(e){var t=this.getNode(e);return null==t?0:t.df},t.InvertedIndex.prototype.removeToken=function(e,t){if(e){var n=this.getNode(e);null!=n&&t in n.docs&&(delete n.docs[t],n.df-=1)}},t.InvertedIndex.prototype.expandToken=function(e,t,n){if(null==e||""==e)return[];var t=t||[];if(void 0==n&&(n=this.getNode(e),null==n))return t;n.df>0&&t.push(e);for(var i in n)"docs"!==i&&"df"!==i&&this.expandToken(e+i,t,n[i]);return t},t.InvertedIndex.prototype.toJSON=function(){return{root:this.root}},t.Configuration=function(e,n){var e=e||"";if(void 0==n||null==n)throw new Error("fields should not be null");this.config={};var i;try{i=JSON.parse(e),this.buildUserConfig(i,n)}catch(o){t.utils.warn("user configuration parse failed, will use default configuration"),this.buildDefaultConfig(n)}},t.Configuration.prototype.buildDefaultConfig=function(e){this.reset(),e.forEach(function(e){this.config[e]={boost:1,bool:"OR",expand:!1}},this)},t.Configuration.prototype.buildUserConfig=function(e,n){var i="OR",o=!1;if(this.reset(),"bool"in e&&(i=e.bool||i),"expand"in e&&(o=e.expand||o),"fields"in e)for(var r in e.fields)if(n.indexOf(r)>-1){var s=e.fields[r],u=o;void 0!=s.expand&&(u=s.expand),this.config[r]={boost:s.boost||0===s.boost?s.boost:1,bool:s.bool||i,expand:u}}else t.utils.warn("field name in user configuration not found in index instance fields");else this.addAllFields2UserConfig(i,o,n)},t.Configuration.prototype.addAllFields2UserConfig=function(e,t,n){n.forEach(function(n){this.config[n]={boost:1,bool:e,expand:t}},this)},t.Configuration.prototype.get=function(){return this.config},t.Configuration.prototype.reset=function(){this.config={}},lunr.SortedSet=function(){this.length=0,this.elements=[]},lunr.SortedSet.load=function(e){var t=new this;return t.elements=e,t.length=e.length,t},lunr.SortedSet.prototype.add=function(){var e,t;for(e=0;e<arguments.length;e++)t=arguments[e],~this.indexOf(t)||this.elements.splice(this.locationFor(t),0,t);this.length=this.elements.length},lunr.SortedSet.prototype.toArray=function(){return this.elements.slice()},lunr.SortedSet.prototype.map=function(e,t){return this.elements.map(e,t)},lunr.SortedSet.prototype.forEach=function(e,t){return this.elements.forEach(e,t)},lunr.SortedSet.prototype.indexOf=function(e){for(var t=0,n=this.elements.length,i=n-t,o=t+Math.floor(i/2),r=this.elements[o];i>1;){if(r===e)return o;e>r&&(t=o),r>e&&(n=o),i=n-t,o=t+Math.floor(i/2),r=this.elements[o]}return r===e?o:-1},lunr.SortedSet.prototype.locationFor=function(e){for(var t=0,n=this.elements.length,i=n-t,o=t+Math.floor(i/2),r=this.elements[o];i>1;)e>r&&(t=o),r>e&&(n=o),i=n-t,o=t+Math.floor(i/2),r=this.elements[o];return r>e?o:e>r?o+1:void 0},lunr.SortedSet.prototype.intersect=function(e){for(var t=new lunr.SortedSet,n=0,i=0,o=this.length,r=e.length,s=this.elements,u=e.elements;;){if(n>o-1||i>r-1)break;s[n]!==u[i]?s[n]<u[i]?n++:s[n]>u[i]&&i++:(t.add(s[n]),n++,i++)}return t},lunr.SortedSet.prototype.clone=function(){var e=new lunr.SortedSet;return e.elements=this.toArray(),e.length=e.elements.length,e},lunr.SortedSet.prototype.union=function(e){var t,n,i;this.length>=e.length?(t=this,n=e):(t=e,n=this),i=t.clone();for(var o=0,r=n.toArray();o<r.length;o++)i.add(r[o]);return i},lunr.SortedSet.prototype.toJSON=function(){return this.toArray()},function(e,t){"function"==typeof define&&define.amd?define(t):"object"==typeof exports?module.exports=t():e.elasticlunr=t()}(this,function(){return t})}();
    /** pdoc search index */const docs = [{"fullname": "sloths.ImageClassifier", "modulename": "sloths.ImageClassifier", "kind": "module", "doc": "<p></p>\n"}, {"fullname": "sloths.ImageClassifier.ImageClassifier", "modulename": "sloths.ImageClassifier", "qualname": "ImageClassifier", "kind": "class", "doc": "<p>A convolutional neural network for image classification.</p>\n\n<p>This LightningModule defines a simple CNN with three convolutional\nblocks followed by fully connected layers. It logs training and\nvalidation loss/accuracy during training.</p>\n\n<h2 id=\"parameters\">Parameters</h2>\n\n<p>num_classes : int, optional\n    Number of output classes for classification. Default is 2.\nlr : float, optional\n    Learning rate for the Adam optimizer. Default is 1e-3.</p>\n\n<h2 id=\"attributes\">Attributes</h2>\n\n<p>model : torch.nn.Sequential\n    The convolutional neural network.\nloss_fn : torch.nn.CrossEntropyLoss\n    Loss function used for training.</p>\n\n<h2 id=\"methods\">Methods</h2>\n\n<p>forward(x)\n    Forward pass through the network.\ntraining_step(batch, batch_idx)\n    Computes loss and accuracy on a training batch, logs results.\nvalidation_step(batch, batch_idx)\n    Computes loss and accuracy on a validation batch, logs results.\nconfigure_optimizers()\n    Returns the optimizer (Adam).</p>\n\n<h2 id=\"see-also\">See Also</h2>\n\n<p>pl.LightningModule : Base class for all PyTorch Lightning models.</p>\n\n<h2 id=\"examples\">Examples</h2>\n\n<div class=\"pdoc-code codehilite\">\n<pre><span></span><code><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">model</span> <span class=\"o\">=</span> <span class=\"n\">ImageClassifier</span><span class=\"p\">(</span><span class=\"n\">num_classes</span><span class=\"o\">=</span><span class=\"mi\">10</span><span class=\"p\">)</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">x</span> <span class=\"o\">=</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">randn</span><span class=\"p\">(</span><span class=\"mi\">8</span><span class=\"p\">,</span> <span class=\"mi\">3</span><span class=\"p\">,</span> <span class=\"mi\">128</span><span class=\"p\">,</span> <span class=\"mi\">128</span><span class=\"p\">)</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">out</span> <span class=\"o\">=</span> <span class=\"n\">model</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">)</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">out</span><span class=\"o\">.</span><span class=\"n\">shape</span>\n<span class=\"go\">torch.Size([8, 10])</span>\n</code></pre>\n</div>\n", "bases": "pytorch_lightning.core.module.LightningModule"}, {"fullname": "sloths.ImageClassifier.ImageClassifier.__init__", "modulename": "sloths.ImageClassifier", "qualname": "ImageClassifier.__init__", "kind": "function", "doc": "<p>Attributes:\n    prepare_data_per_node:\n        If True, each LOCAL_RANK=0 will call prepare data.\n        Otherwise only NODE_RANK=0, LOCAL_RANK=0 will prepare data.\n    allow_zero_length_dataloader_with_multiple_devices:\n        If True, dataloader with zero length within local rank is allowed.\n        Default value is False.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">num_classes</span><span class=\"o\">=</span><span class=\"mi\">2</span>, </span><span class=\"param\"><span class=\"n\">lr</span><span class=\"o\">=</span><span class=\"mf\">0.001</span></span>)</span>"}, {"fullname": "sloths.ImageClassifier.ImageClassifier.model", "modulename": "sloths.ImageClassifier", "qualname": "ImageClassifier.model", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sloths.ImageClassifier.ImageClassifier.loss_fn", "modulename": "sloths.ImageClassifier", "qualname": "ImageClassifier.loss_fn", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sloths.ImageClassifier.ImageClassifier.forward", "modulename": "sloths.ImageClassifier", "qualname": "ImageClassifier.forward", "kind": "function", "doc": "<p>Same as <code>torch.nn.Module.forward()</code>.</p>\n\n<p>Args:\n    <em>args: Whatever you decide to pass into the forward method.\n    *</em>kwargs: Keyword arguments are also possible.</p>\n\n<p>Return:\n    Your model's output</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">x</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sloths.ImageClassifier.ImageClassifier.training_step", "modulename": "sloths.ImageClassifier", "qualname": "ImageClassifier.training_step", "kind": "function", "doc": "<p>Here you compute and return the training loss and some additional metrics for e.g. the progress bar or\nlogger.</p>\n\n<p>Args:\n    batch: The output of your data iterable, normally a <code>~torch.utils.data.DataLoader</code>.\n    batch_idx: The index of this batch.\n    dataloader_idx: The index of the dataloader that produced this batch.\n        (only if multiple dataloaders used)</p>\n\n<p>Return:\n    - <code>~torch.Tensor</code> - The loss tensor\n    - <code>dict</code> - A dictionary which can include any keys, but must include the key <code>'loss'</code> in the case of\n      automatic optimization.\n    - <code>None</code> - In automatic optimization, this will skip to the next batch (but is not supported for\n      multi-GPU, TPU, or DeepSpeed). For manual optimization, this has no special meaning, as returning\n      the loss is not required.</p>\n\n<p>In this step you'd normally do the forward pass and calculate the loss for a batch.\nYou can also do fancier things like multiple forward passes or something model specific.</p>\n\n<p>Example::</p>\n\n<pre><code>def training_step(self, batch, batch_idx):\n    x, y, z = batch\n    out = self.encoder(x)\n    loss = self.loss(out, x)\n    return loss\n</code></pre>\n\n<p>To use multiple optimizers, you can switch to 'manual optimization' and control their stepping:</p>\n\n<div class=\"pdoc-code codehilite\">\n<pre><span></span><code><span class=\"k\">def</span><span class=\"w\"> </span><span class=\"fm\">__init__</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">):</span>\n    <span class=\"nb\">super</span><span class=\"p\">()</span><span class=\"o\">.</span><span class=\"fm\">__init__</span><span class=\"p\">()</span>\n    <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">automatic_optimization</span> <span class=\"o\">=</span> <span class=\"kc\">False</span>\n\n\n<span class=\"c1\"># Multiple optimizers (e.g.: GANs)</span>\n<span class=\"k\">def</span><span class=\"w\"> </span><span class=\"nf\">training_step</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">batch</span><span class=\"p\">,</span> <span class=\"n\">batch_idx</span><span class=\"p\">):</span>\n    <span class=\"n\">opt1</span><span class=\"p\">,</span> <span class=\"n\">opt2</span> <span class=\"o\">=</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">optimizers</span><span class=\"p\">()</span>\n\n    <span class=\"c1\"># do training_step with encoder</span>\n    <span class=\"o\">...</span>\n    <span class=\"n\">opt1</span><span class=\"o\">.</span><span class=\"n\">step</span><span class=\"p\">()</span>\n    <span class=\"c1\"># do training_step with decoder</span>\n    <span class=\"o\">...</span>\n    <span class=\"n\">opt2</span><span class=\"o\">.</span><span class=\"n\">step</span><span class=\"p\">()</span>\n</code></pre>\n</div>\n\n<p>Note:\n    When <code>accumulate_grad_batches</code> &gt; 1, the loss returned here will be automatically\n    normalized by <code>accumulate_grad_batches</code> internally.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">batch</span>, </span><span class=\"param\"><span class=\"n\">batch_idx</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sloths.ImageClassifier.ImageClassifier.validation_step", "modulename": "sloths.ImageClassifier", "qualname": "ImageClassifier.validation_step", "kind": "function", "doc": "<p>Operates on a single batch of data from the validation set. In this step you'd might generate examples or\ncalculate anything of interest like accuracy.</p>\n\n<p>Args:\n    batch: The output of your data iterable, normally a <code>~torch.utils.data.DataLoader</code>.\n    batch_idx: The index of this batch.\n    dataloader_idx: The index of the dataloader that produced this batch.\n        (only if multiple dataloaders used)</p>\n\n<p>Return:\n    - <code>~torch.Tensor</code> - The loss tensor\n    - <code>dict</code> - A dictionary. Can include any keys, but must include the key <code>'loss'</code>.\n    - <code>None</code> - Skip to the next batch.</p>\n\n<div class=\"pdoc-code codehilite\">\n<pre><span></span><code><span class=\"c1\"># if you have one val dataloader:</span>\n<span class=\"k\">def</span><span class=\"w\"> </span><span class=\"nf\">validation_step</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">batch</span><span class=\"p\">,</span> <span class=\"n\">batch_idx</span><span class=\"p\">):</span> <span class=\"o\">...</span>\n\n\n<span class=\"c1\"># if you have multiple val dataloaders:</span>\n<span class=\"k\">def</span><span class=\"w\"> </span><span class=\"nf\">validation_step</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">batch</span><span class=\"p\">,</span> <span class=\"n\">batch_idx</span><span class=\"p\">,</span> <span class=\"n\">dataloader_idx</span><span class=\"o\">=</span><span class=\"mi\">0</span><span class=\"p\">):</span> <span class=\"o\">...</span>\n</code></pre>\n</div>\n\n<p>Examples::</p>\n\n<pre><code># CASE 1: A single validation dataset\ndef validation_step(self, batch, batch_idx):\n    x, y = batch\n\n    # implement your own\n    out = self(x)\n    loss = self.loss(out, y)\n\n    # log 6 example images\n    # or generated text... or whatever\n    sample_imgs = x[:6]\n    grid = torchvision.utils.make_grid(sample_imgs)\n    self.logger.experiment.add_image('example_images', grid, 0)\n\n    # calculate acc\n    labels_hat = torch.argmax(out, dim=1)\n    val_acc = torch.sum(y == labels_hat).item() / (len(y) * 1.0)\n\n    # log the outputs!\n    self.log_dict({'val_loss': loss, 'val_acc': val_acc})\n</code></pre>\n\n<p>If you pass in multiple val dataloaders, <code>validation_step()</code> will have an additional argument. We recommend\nsetting the default value of 0 so that you can quickly switch between single and multiple dataloaders.</p>\n\n<div class=\"pdoc-code codehilite\">\n<pre><span></span><code><span class=\"c1\"># CASE 2: multiple validation dataloaders</span>\n<span class=\"k\">def</span><span class=\"w\"> </span><span class=\"nf\">validation_step</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">batch</span><span class=\"p\">,</span> <span class=\"n\">batch_idx</span><span class=\"p\">,</span> <span class=\"n\">dataloader_idx</span><span class=\"o\">=</span><span class=\"mi\">0</span><span class=\"p\">):</span>\n    <span class=\"c1\"># dataloader_idx tells you which dataset this is.</span>\n    <span class=\"n\">x</span><span class=\"p\">,</span> <span class=\"n\">y</span> <span class=\"o\">=</span> <span class=\"n\">batch</span>\n\n    <span class=\"c1\"># implement your own</span>\n    <span class=\"n\">out</span> <span class=\"o\">=</span> <span class=\"bp\">self</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">)</span>\n\n    <span class=\"k\">if</span> <span class=\"n\">dataloader_idx</span> <span class=\"o\">==</span> <span class=\"mi\">0</span><span class=\"p\">:</span>\n        <span class=\"n\">loss</span> <span class=\"o\">=</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">loss0</span><span class=\"p\">(</span><span class=\"n\">out</span><span class=\"p\">,</span> <span class=\"n\">y</span><span class=\"p\">)</span>\n    <span class=\"k\">else</span><span class=\"p\">:</span>\n        <span class=\"n\">loss</span> <span class=\"o\">=</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">loss1</span><span class=\"p\">(</span><span class=\"n\">out</span><span class=\"p\">,</span> <span class=\"n\">y</span><span class=\"p\">)</span>\n\n    <span class=\"c1\"># calculate acc</span>\n    <span class=\"n\">labels_hat</span> <span class=\"o\">=</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">argmax</span><span class=\"p\">(</span><span class=\"n\">out</span><span class=\"p\">,</span> <span class=\"n\">dim</span><span class=\"o\">=</span><span class=\"mi\">1</span><span class=\"p\">)</span>\n    <span class=\"n\">acc</span> <span class=\"o\">=</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">sum</span><span class=\"p\">(</span><span class=\"n\">y</span> <span class=\"o\">==</span> <span class=\"n\">labels_hat</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">item</span><span class=\"p\">()</span> <span class=\"o\">/</span> <span class=\"p\">(</span><span class=\"nb\">len</span><span class=\"p\">(</span><span class=\"n\">y</span><span class=\"p\">)</span> <span class=\"o\">*</span> <span class=\"mf\">1.0</span><span class=\"p\">)</span>\n\n    <span class=\"c1\"># log the outputs separately for each dataloader</span>\n    <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">log_dict</span><span class=\"p\">({</span><span class=\"sa\">f</span><span class=\"s2\">&quot;val_loss_</span><span class=\"si\">{</span><span class=\"n\">dataloader_idx</span><span class=\"si\">}</span><span class=\"s2\">&quot;</span><span class=\"p\">:</span> <span class=\"n\">loss</span><span class=\"p\">,</span> <span class=\"sa\">f</span><span class=\"s2\">&quot;val_acc_</span><span class=\"si\">{</span><span class=\"n\">dataloader_idx</span><span class=\"si\">}</span><span class=\"s2\">&quot;</span><span class=\"p\">:</span> <span class=\"n\">acc</span><span class=\"p\">})</span>\n</code></pre>\n</div>\n\n<p>Note:\n    If you don't need to validate you don't need to implement this method.</p>\n\n<p>Note:\n    When the <code>validation_step()</code> is called, the model has been put in eval mode\n    and PyTorch gradients have been disabled. At the end of validation,\n    the model goes back to training mode and gradients are enabled.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">batch</span>, </span><span class=\"param\"><span class=\"n\">batch_idx</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sloths.ImageClassifier.ImageClassifier.configure_optimizers", "modulename": "sloths.ImageClassifier", "qualname": "ImageClassifier.configure_optimizers", "kind": "function", "doc": "<p>Choose what optimizers and learning-rate schedulers to use in your optimization. Normally you'd need one.\nBut in the case of GANs or similar you might have multiple. Optimization with multiple optimizers only works in\nthe manual optimization mode.</p>\n\n<p>Return:\n    Any of these 6 options.</p>\n\n<pre><code>- **Single optimizer**.\n- **List or Tuple** of optimizers.\n- **Two lists** - The first list has multiple optimizers, and the second has multiple LR schedulers\n  (or multiple ``lr_scheduler_config``).\n- **Dictionary**, with an ``\"optimizer\"`` key, and (optionally) a ``\"lr_scheduler\"``\n  key whose value is a single LR scheduler or ``lr_scheduler_config``.\n- **None** - Fit will run without any optimizer.\n</code></pre>\n\n<p>The <code>lr_scheduler_config</code> is a dictionary which contains the scheduler and its associated configuration.\nThe default configuration is shown below.</p>\n\n<div class=\"pdoc-code codehilite\">\n<pre><span></span><code><span class=\"n\">lr_scheduler_config</span> <span class=\"o\">=</span> <span class=\"p\">{</span>\n    <span class=\"c1\"># REQUIRED: The scheduler instance</span>\n    <span class=\"s2\">&quot;scheduler&quot;</span><span class=\"p\">:</span> <span class=\"n\">lr_scheduler</span><span class=\"p\">,</span>\n    <span class=\"c1\"># The unit of the scheduler&#39;s step size, could also be &#39;step&#39;.</span>\n    <span class=\"c1\"># &#39;epoch&#39; updates the scheduler on epoch end whereas &#39;step&#39;</span>\n    <span class=\"c1\"># updates it after a optimizer update.</span>\n    <span class=\"s2\">&quot;interval&quot;</span><span class=\"p\">:</span> <span class=\"s2\">&quot;epoch&quot;</span><span class=\"p\">,</span>\n    <span class=\"c1\"># How many epochs/steps should pass between calls to</span>\n    <span class=\"c1\"># `scheduler.step()`. 1 corresponds to updating the learning</span>\n    <span class=\"c1\"># rate after every epoch/step.</span>\n    <span class=\"s2\">&quot;frequency&quot;</span><span class=\"p\">:</span> <span class=\"mi\">1</span><span class=\"p\">,</span>\n    <span class=\"c1\"># Metric to monitor for schedulers like `ReduceLROnPlateau`</span>\n    <span class=\"s2\">&quot;monitor&quot;</span><span class=\"p\">:</span> <span class=\"s2\">&quot;val_loss&quot;</span><span class=\"p\">,</span>\n    <span class=\"c1\"># If set to `True`, will enforce that the value specified &#39;monitor&#39;</span>\n    <span class=\"c1\"># is available when the scheduler is updated, thus stopping</span>\n    <span class=\"c1\"># training if not found. If set to `False`, it will only produce a warning</span>\n    <span class=\"s2\">&quot;strict&quot;</span><span class=\"p\">:</span> <span class=\"kc\">True</span><span class=\"p\">,</span>\n    <span class=\"c1\"># If using the `LearningRateMonitor` callback to monitor the</span>\n    <span class=\"c1\"># learning rate progress, this keyword can be used to specify</span>\n    <span class=\"c1\"># a custom logged name</span>\n    <span class=\"s2\">&quot;name&quot;</span><span class=\"p\">:</span> <span class=\"kc\">None</span><span class=\"p\">,</span>\n<span class=\"p\">}</span>\n</code></pre>\n</div>\n\n<p>When there are schedulers in which the <code>.step()</code> method is conditioned on a value, such as the\n<code>torch.optim.lr_scheduler.ReduceLROnPlateau</code> scheduler, Lightning requires that the\n<code>lr_scheduler_config</code> contains the keyword <code>\"monitor\"</code> set to the metric name that the scheduler\nshould be conditioned on.</p>\n\n<p>.. testcode::</p>\n\n<pre><code># The ReduceLROnPlateau scheduler requires a monitor\ndef configure_optimizers(self):\n    optimizer = Adam(...)\n    return {\n        \"optimizer\": optimizer,\n        \"lr_scheduler\": {\n            \"scheduler\": ReduceLROnPlateau(optimizer, ...),\n            \"monitor\": \"metric_to_track\",\n            \"frequency\": \"indicates how often the metric is updated\",\n            # If \"monitor\" references validation metrics, then \"frequency\" should be set to a\n            # multiple of \"trainer.check_val_every_n_epoch\".\n        },\n    }\n\n\n# In the case of two optimizers, only one using the ReduceLROnPlateau scheduler\ndef configure_optimizers(self):\n    optimizer1 = Adam(...)\n    optimizer2 = SGD(...)\n    scheduler1 = ReduceLROnPlateau(optimizer1, ...)\n    scheduler2 = LambdaLR(optimizer2, ...)\n    return (\n        {\n            \"optimizer\": optimizer1,\n            \"lr_scheduler\": {\n                \"scheduler\": scheduler1,\n                \"monitor\": \"metric_to_track\",\n            },\n        },\n        {\"optimizer\": optimizer2, \"lr_scheduler\": scheduler2},\n    )\n</code></pre>\n\n<p>Metrics can be made available to monitor by simply logging it using\n<code>self.log('metric_to_track', metric_val)</code> in your <code>~pytorch_lightning.core.LightningModule</code>.</p>\n\n<p>Note:\n    Some things to know:</p>\n\n<pre><code>- Lightning calls ``.backward()`` and ``.step()`` automatically in case of automatic optimization.\n- If a learning rate scheduler is specified in ``configure_optimizers()`` with key\n  ``\"interval\"`` (default \"epoch\") in the scheduler configuration, Lightning will call\n  the scheduler's ``.step()`` method automatically in case of automatic optimization.\n- If you use 16-bit precision (``precision=16``), Lightning will automatically handle the optimizer.\n- If you use `torch.optim.LBFGS`, Lightning handles the closure function automatically for you.\n- If you use multiple optimizers, you will have to switch to 'manual optimization' mode and step them\n  yourself.\n- If you need to control how often the optimizer steps, override the `optimizer_step()` hook.\n</code></pre>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sloths.MetricsCallback", "modulename": "sloths.MetricsCallback", "kind": "module", "doc": "<p></p>\n"}, {"fullname": "sloths.MetricsCallback.MetricsCallback", "modulename": "sloths.MetricsCallback", "qualname": "MetricsCallback", "kind": "class", "doc": "<p>A PyTorch Lightning callback for collecting metrics across epochs.</p>\n\n<p>This callback stores the training and validation loss/accuracy at\nthe end of each epoch, which can be used for plotting or reporting.</p>\n\n<h2 id=\"attributes\">Attributes</h2>\n\n<p>train_loss : list of float\n    Training loss per epoch.\nval_loss : list of float\n    Validation loss per epoch.\ntrain_acc : list of float\n    Training accuracy per epoch.\nval_acc : list of float\n    Validation accuracy per epoch.</p>\n\n<h2 id=\"methods\">Methods</h2>\n\n<p>on_train_epoch_end(trainer, pl_module)\n    Records training loss and accuracy after each epoch.\non_validation_epoch_end(trainer, pl_module)\n    Records validation loss and accuracy after each epoch.</p>\n\n<h2 id=\"see-also\">See Also</h2>\n\n<p>pytorch_lightning.callbacks.Callback : Base class for callbacks.</p>\n\n<h2 id=\"examples\">Examples</h2>\n\n<div class=\"pdoc-code codehilite\">\n<pre><span></span><code><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">metrics_cb</span> <span class=\"o\">=</span> <span class=\"n\">MetricsCallback</span><span class=\"p\">()</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">trainer</span> <span class=\"o\">=</span> <span class=\"n\">pl</span><span class=\"o\">.</span><span class=\"n\">Trainer</span><span class=\"p\">(</span><span class=\"n\">callbacks</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"n\">metrics_cb</span><span class=\"p\">],</span> <span class=\"n\">max_epochs</span><span class=\"o\">=</span><span class=\"mi\">3</span><span class=\"p\">)</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">trainer</span><span class=\"o\">.</span><span class=\"n\">fit</span><span class=\"p\">(</span><span class=\"n\">model</span><span class=\"p\">,</span> <span class=\"n\">train_loader</span><span class=\"p\">,</span> <span class=\"n\">val_loader</span><span class=\"p\">)</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"n\">metrics_cb</span><span class=\"o\">.</span><span class=\"n\">train_acc</span><span class=\"p\">)</span>\n<span class=\"go\">[0.75, 0.82, 0.88]</span>\n</code></pre>\n</div>\n", "bases": "pytorch_lightning.callbacks.callback.Callback"}, {"fullname": "sloths.MetricsCallback.MetricsCallback.train_loss", "modulename": "sloths.MetricsCallback", "qualname": "MetricsCallback.train_loss", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sloths.MetricsCallback.MetricsCallback.val_loss", "modulename": "sloths.MetricsCallback", "qualname": "MetricsCallback.val_loss", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sloths.MetricsCallback.MetricsCallback.train_acc", "modulename": "sloths.MetricsCallback", "qualname": "MetricsCallback.train_acc", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sloths.MetricsCallback.MetricsCallback.val_acc", "modulename": "sloths.MetricsCallback", "qualname": "MetricsCallback.val_acc", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "sloths.MetricsCallback.MetricsCallback.on_train_epoch_end", "modulename": "sloths.MetricsCallback", "qualname": "MetricsCallback.on_train_epoch_end", "kind": "function", "doc": "<p>Called when the train epoch ends.</p>\n\n<p>To access all batch outputs at the end of the epoch, you can cache step outputs as an attribute of the\n<code>pytorch_lightning.core.LightningModule</code> and access them in this hook:</p>\n\n<div class=\"pdoc-code codehilite\">\n<pre><span></span><code><span class=\"k\">class</span><span class=\"w\"> </span><span class=\"nc\">MyLightningModule</span><span class=\"p\">(</span><span class=\"n\">L</span><span class=\"o\">.</span><span class=\"n\">LightningModule</span><span class=\"p\">):</span>\n    <span class=\"k\">def</span><span class=\"w\"> </span><span class=\"fm\">__init__</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">):</span>\n        <span class=\"nb\">super</span><span class=\"p\">()</span><span class=\"o\">.</span><span class=\"fm\">__init__</span><span class=\"p\">()</span>\n        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">training_step_outputs</span> <span class=\"o\">=</span> <span class=\"p\">[]</span>\n\n    <span class=\"k\">def</span><span class=\"w\"> </span><span class=\"nf\">training_step</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">):</span>\n        <span class=\"n\">loss</span> <span class=\"o\">=</span> <span class=\"o\">...</span>\n        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">training_step_outputs</span><span class=\"o\">.</span><span class=\"n\">append</span><span class=\"p\">(</span><span class=\"n\">loss</span><span class=\"p\">)</span>\n        <span class=\"k\">return</span> <span class=\"n\">loss</span>\n\n\n<span class=\"k\">class</span><span class=\"w\"> </span><span class=\"nc\">MyCallback</span><span class=\"p\">(</span><span class=\"n\">L</span><span class=\"o\">.</span><span class=\"n\">Callback</span><span class=\"p\">):</span>\n    <span class=\"k\">def</span><span class=\"w\"> </span><span class=\"nf\">on_train_epoch_end</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">trainer</span><span class=\"p\">,</span> <span class=\"n\">pl_module</span><span class=\"p\">):</span>\n        <span class=\"c1\"># do something with all training_step outputs, for example:</span>\n        <span class=\"n\">epoch_mean</span> <span class=\"o\">=</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">stack</span><span class=\"p\">(</span><span class=\"n\">pl_module</span><span class=\"o\">.</span><span class=\"n\">training_step_outputs</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">mean</span><span class=\"p\">()</span>\n        <span class=\"n\">pl_module</span><span class=\"o\">.</span><span class=\"n\">log</span><span class=\"p\">(</span><span class=\"s2\">&quot;training_epoch_mean&quot;</span><span class=\"p\">,</span> <span class=\"n\">epoch_mean</span><span class=\"p\">)</span>\n        <span class=\"c1\"># free up the memory</span>\n        <span class=\"n\">pl_module</span><span class=\"o\">.</span><span class=\"n\">training_step_outputs</span><span class=\"o\">.</span><span class=\"n\">clear</span><span class=\"p\">()</span>\n</code></pre>\n</div>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">trainer</span>, </span><span class=\"param\"><span class=\"n\">pl_module</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sloths.MetricsCallback.MetricsCallback.on_validation_epoch_end", "modulename": "sloths.MetricsCallback", "qualname": "MetricsCallback.on_validation_epoch_end", "kind": "function", "doc": "<p>Called when the val epoch ends.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">trainer</span>, </span><span class=\"param\"><span class=\"n\">pl_module</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sloths.imshow", "modulename": "sloths.imshow", "kind": "module", "doc": "<p></p>\n"}, {"fullname": "sloths.imshow.imshow", "modulename": "sloths.imshow", "qualname": "imshow", "kind": "function", "doc": "<p>Display a single image tensor with a title.</p>\n\n<p>This function denormalizes the input tensor (assuming\nvalues were normalized around mean=0.5, std=0.5),\nconverts it to a NumPy array, and displays it with matplotlib.</p>\n\n<h2 id=\"parameters\">Parameters</h2>\n\n<p>img : torch.Tensor\n    Image tensor of shape (C, H, W) normalized to [-1, 1].\ntitle : str\n    Title to display above the image.</p>\n\n<h2 id=\"returns\">Returns</h2>\n\n<p>None\n    Displays the image using matplotlib.</p>\n\n<h2 id=\"see-also\">See Also</h2>\n\n<p>matplotlib.pyplot.imshow : Display an image.\ntorchvision.transforms.Normalize : Normalization used in preprocessing.</p>\n\n<h2 id=\"examples\">Examples</h2>\n\n<div class=\"pdoc-code codehilite\">\n<pre><span></span><code><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">images</span><span class=\"p\">,</span> <span class=\"n\">labels</span> <span class=\"o\">=</span> <span class=\"nb\">next</span><span class=\"p\">(</span><span class=\"nb\">iter</span><span class=\"p\">(</span><span class=\"n\">train_loader</span><span class=\"p\">))</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">imshow</span><span class=\"p\">(</span><span class=\"n\">images</span><span class=\"p\">[</span><span class=\"mi\">0</span><span class=\"p\">],</span> <span class=\"s2\">&quot;Example image&quot;</span><span class=\"p\">)</span>\n</code></pre>\n</div>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">img</span>, </span><span class=\"param\"><span class=\"n\">title</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sloths.visualizations", "modulename": "sloths.visualizations", "kind": "module", "doc": "<p></p>\n"}, {"fullname": "sloths.visualizations.generate_visualizations", "modulename": "sloths.visualizations", "qualname": "generate_visualizations", "kind": "function", "doc": "<p>Generate and save visualizations for dataset exploration and model performance.</p>\n\n<p>This function creates multiple plots summarizing dataset characteristics,\ntraining metrics, and model evaluation results. All figures are saved\nunder <code>reports/figures/</code>.</p>\n\n<h2 id=\"parameters\">Parameters</h2>\n\n<p>train_loader : torch.utils.data.DataLoader\n    DataLoader containing the training dataset.\nclass_names : list of str\n    List of class labels.\nclass_dist : pandas.DataFrame\n    DataFrame with 'Class' and 'Count' columns describing class distribution.\nwidths : list or np.ndarray\n    List of image widths in the dataset.\nheights : list or np.ndarray\n    List of image heights in the dataset.\nmetrics_cb : object\n    Callback-like object containing train/val loss and accuracy lists.\ncm : np.ndarray\n    Confusion matrix for model predictions.\nmean_pred : np.ndarray\n    Mean predicted probabilities for calibration curve.\nfrac_pos : np.ndarray\n    Fraction of positive samples for calibration curve.\ncalib_error : float\n    Calibration error value to display on the plot.\ntop_samples : list of int\n    Indices of the most misclassified samples.\nsamples : torch.Tensor\n    Tensor containing sample images.\nlabels_np : np.ndarray\n    Ground truth labels corresponding to samples.\nlosses : np.ndarray\n    Loss values for each sample.\npred_probs : np.ndarray\n    Predicted probabilities for each sample.\ncolor_palette : str, optional\n    Matplotlib color palette name. Default is \"default\".</p>\n\n<h2 id=\"returns\">Returns</h2>\n\n<p>None</p>\n\n<h2 id=\"examples\">Examples</h2>\n\n<div class=\"pdoc-code codehilite\">\n<pre><span></span><code><span class=\"gp\">&gt;&gt;&gt; </span><span class=\"kn\">from</span><span class=\"w\"> </span><span class=\"nn\">visualizations</span><span class=\"w\"> </span><span class=\"kn\">import</span> <span class=\"n\">generate_visualizations</span>\n<span class=\"gp\">&gt;&gt;&gt; </span><span class=\"n\">generate_visualizations</span><span class=\"p\">(</span><span class=\"n\">train_loader</span><span class=\"p\">,</span> <span class=\"n\">class_names</span><span class=\"p\">,</span> <span class=\"n\">class_dist</span><span class=\"p\">,</span> <span class=\"n\">widths</span><span class=\"p\">,</span> <span class=\"n\">heights</span><span class=\"p\">,</span>\n<span class=\"gp\">... </span>                        <span class=\"n\">metrics_cb</span><span class=\"p\">,</span> <span class=\"n\">cm</span><span class=\"p\">,</span> <span class=\"n\">mean_pred</span><span class=\"p\">,</span> <span class=\"n\">frac_pos</span><span class=\"p\">,</span> <span class=\"n\">calib_error</span><span class=\"p\">,</span>\n<span class=\"gp\">... </span>                        <span class=\"n\">top_samples</span><span class=\"p\">,</span> <span class=\"n\">samples</span><span class=\"p\">,</span> <span class=\"n\">labels_np</span><span class=\"p\">,</span> <span class=\"n\">losses</span><span class=\"p\">,</span> <span class=\"n\">pred_probs</span><span class=\"p\">,</span>\n<span class=\"gp\">... </span>                        <span class=\"n\">color_palette</span><span class=\"o\">=</span><span class=\"s2\">&quot;viridis&quot;</span><span class=\"p\">)</span>\n</code></pre>\n</div>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">train_loader</span>,</span><span class=\"param\">\t<span class=\"n\">class_names</span>,</span><span class=\"param\">\t<span class=\"n\">class_dist</span>,</span><span class=\"param\">\t<span class=\"n\">widths</span>,</span><span class=\"param\">\t<span class=\"n\">heights</span>,</span><span class=\"param\">\t<span class=\"n\">metrics_cb</span>,</span><span class=\"param\">\t<span class=\"n\">cm</span>,</span><span class=\"param\">\t<span class=\"n\">mean_pred</span>,</span><span class=\"param\">\t<span class=\"n\">frac_pos</span>,</span><span class=\"param\">\t<span class=\"n\">calib_error</span>,</span><span class=\"param\">\t<span class=\"n\">top_samples</span>,</span><span class=\"param\">\t<span class=\"n\">samples</span>,</span><span class=\"param\">\t<span class=\"n\">labels_np</span>,</span><span class=\"param\">\t<span class=\"n\">losses</span>,</span><span class=\"param\">\t<span class=\"n\">pred_probs</span>,</span><span class=\"param\">\t<span class=\"n\">color_palette</span><span class=\"o\">=</span><span class=\"s1\">&#39;default&#39;</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sloths.demo.app_gradio", "modulename": "sloths.demo.app_gradio", "kind": "module", "doc": "<p></p>\n"}, {"fullname": "sloths.demo.app_gradio.fig_to_pil", "modulename": "sloths.demo.app_gradio", "qualname": "fig_to_pil", "kind": "function", "doc": "<p>Convert a matplotlib figure to a PIL image.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">fig</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sloths.demo.app_gradio.TEMP_DATA_DIR", "modulename": "sloths.demo.app_gradio", "qualname": "TEMP_DATA_DIR", "kind": "variable", "doc": "<p></p>\n", "default_value": "None"}, {"fullname": "sloths.demo.app_gradio.KAGGLE_JSON_PATH", "modulename": "sloths.demo.app_gradio", "qualname": "KAGGLE_JSON_PATH", "kind": "variable", "doc": "<p></p>\n", "default_value": "&#x27;/home/alumno/.config/kaggle/kaggle.json&#x27;"}, {"fullname": "sloths.demo.app_gradio.download_kaggle_dataset", "modulename": "sloths.demo.app_gradio", "qualname": "download_kaggle_dataset", "kind": "function", "doc": "<p>Downloads the Kaggle dataset 'Sloths versus Pain au Chocolat' using temporary credentials.\nThe dataset is extracted into a temporary folder, and the 'train' subfolder is used as data source.\nThe download directory is automatically opened in the system file explorer.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">username</span><span class=\"p\">:</span> <span class=\"nb\">str</span>, </span><span class=\"param\"><span class=\"n\">key</span><span class=\"p\">:</span> <span class=\"nb\">str</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sloths.demo.app_gradio.cleanup", "modulename": "sloths.demo.app_gradio", "qualname": "cleanup", "kind": "function", "doc": "<p>Deletes the temporary dataset directory and any Kaggle credentials\nthat were created during the demo.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sloths.demo.app_gradio.analyze_dataset", "modulename": "sloths.demo.app_gradio", "qualname": "analyze_dataset", "kind": "function", "doc": "<p>Analyze dataset structure and visualize key properties.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">data_dir</span>, </span><span class=\"param\"><span class=\"n\">seed</span>, </span><span class=\"param\"><span class=\"n\">img_size</span>, </span><span class=\"param\"><span class=\"n\">color_palette</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sloths.demo.app_gradio.run_experiment", "modulename": "sloths.demo.app_gradio", "qualname": "run_experiment", "kind": "function", "doc": "<p>Train an image classifier and visualize performance metrics.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">data_dir</span>, </span><span class=\"param\"><span class=\"n\">seed</span>, </span><span class=\"param\"><span class=\"n\">img_size</span>, </span><span class=\"param\"><span class=\"n\">batch_size</span>, </span><span class=\"param\"><span class=\"n\">epochs</span>, </span><span class=\"param\"><span class=\"n\">color_palette</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "sloths.demo.app_gradio.main", "modulename": "sloths.demo.app_gradio", "qualname": "main", "kind": "function", "doc": "<p>Launch the interactive Gradio dashboard.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"return-annotation\">):</span></span>", "funcdef": "def"}];

    // mirrored in build-search-index.js (part 1)
    // Also split on html tags. this is a cheap heuristic, but good enough.
    elasticlunr.tokenizer.setSeperator(/[\s\-.;&_'"=,()]+|<[^>]*>/);

    let searchIndex;
    if (docs._isPrebuiltIndex) {
        console.info("using precompiled search index");
        searchIndex = elasticlunr.Index.load(docs);
    } else {
        console.time("building search index");
        // mirrored in build-search-index.js (part 2)
        searchIndex = elasticlunr(function () {
            this.pipeline.remove(elasticlunr.stemmer);
            this.pipeline.remove(elasticlunr.stopWordFilter);
            this.addField("qualname");
            this.addField("fullname");
            this.addField("annotation");
            this.addField("default_value");
            this.addField("signature");
            this.addField("bases");
            this.addField("doc");
            this.setRef("fullname");
        });
        for (let doc of docs) {
            searchIndex.addDoc(doc);
        }
        console.timeEnd("building search index");
    }

    return (term) => searchIndex.search(term, {
        fields: {
            qualname: {boost: 4},
            fullname: {boost: 2},
            annotation: {boost: 2},
            default_value: {boost: 2},
            signature: {boost: 2},
            bases: {boost: 2},
            doc: {boost: 1},
        },
        expand: true
    });
})();